{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#28B463'>RESUBSTITUTION\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#28B463'>Introduction\n",
    "\n",
    "<br>\n",
    "\n",
    "The evaluation method known as resubsitution consists in fitting a model to the same training set we will use for predictions. We will see that resubstitution, although being the simplest evaluation technique, introduces a very optimistic (statistical) bias due to overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SETUP : importing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "#import sklearn.linear_model as lm\n",
    "import sklearn.neighbors as nbr\n",
    "import sklearn.metrics as mtr\n",
    "\n",
    "import utilcompute as uc\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SETUP : reading in the datasets\n",
    "\n",
    "data = np.column_stack( (load_iris().data, load_iris().target) )\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'species']\n",
    "\n",
    "#print('df.shape[0] : ', df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING : deleting features\n",
    "\n",
    "to_delete = []\n",
    "cols = [c for c in df.columns.values.tolist() if (c not in to_delete)]\n",
    "df = df[cols]\n",
    "\n",
    "#print('columns : ', df.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = 'species'\n",
    "if (isinstance(target, list)):\n",
    "    features = [c for c in df.columns.values.tolist() if (c not in target)]\n",
    "else:\n",
    "    features = [c for c in df.columns.values.tolist() if (c != target)]\n",
    "\n",
    "#print('features : ', features)\n",
    "#print('target   : ', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df : \n",
      "\n",
      "{'petal length': 173.96896536339727,\n",
      " 'petal width': 55.48868864572551,\n",
      " 'sepal length': 264.7457109493044,\n",
      " 'sepal width': 97.111605833803296}\n",
      "\n",
      "df_std : \n",
      "\n",
      "{'petal length': 31.397291650719751,\n",
      " 'petal width': 16.141563956997683,\n",
      " 'sepal length': 7.1031134428332869,\n",
      " 'sepal width': 2.0990386257420881}\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING : features standardization\n",
    "\n",
    "vif_dict = uc.compute_vif(df = df, features = features)\n",
    "print('df : ')\n",
    "print()\n",
    "pprint(vif_dict)\n",
    "\n",
    "print()\n",
    "\n",
    "df_std = uc.standardize(df = df, included = features, excluded = target)\n",
    "\n",
    "vif_dict = uc.compute_vif(df = df_std, features = features)\n",
    "print('df_std : ')\n",
    "print()\n",
    "pprint(vif_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING : vif subset selection [reduces multicollinearity]\n",
    "\n",
    "VIF = False\n",
    "\n",
    "if (VIF):\n",
    "    selected_features = uc.vif_best_subset_selection(\n",
    "        vif_threshold = 5, \n",
    "        df = df_std, \n",
    "        features = features, \n",
    "        level = len(features), \n",
    "        debug = False\n",
    "    )\n",
    "    t = uc.concatenate(features, target)\n",
    "    df_std = df_std[t]\n",
    "    \n",
    "    vif_dict = uc.compute_vif(df = df_std, features = selected_features)\n",
    "    pprint(vif_dict)\n",
    "else:\n",
    "    selected_features = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['petal length' 'petal width' 'sepal length' 'sepal width' 'species']\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING : final setup\n",
    "\n",
    "df = df_std\n",
    "features = selected_features\n",
    "\n",
    "print(df_std.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed :  1\n"
     ]
    }
   ],
   "source": [
    "# GLOBAL PARAMETERS\n",
    "\n",
    "s = 1\n",
    "\n",
    "print('seed : ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(s)\n",
    "df_shuffled = df.reindex(np.random.permutation(df.index))    \n",
    "       \n",
    "#model = lm.LogisticRegression()\n",
    "model = nbr.KNeighborsClassifier(n_neighbors = 5)\n",
    "model.fit(df_shuffled[features], df_shuffled[target])\n",
    "y_pred = model.predict(df_shuffled[features])\n",
    "\n",
    "#metrics = uc.compute_classification_metrics(y = df_shuffled[target], y_pred = y_pred)\n",
    "acc = mtr.accuracy_score(y_true = df_shuffled[target], y_pred = y_pred, normalize = True, sample_weight = None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "err :  0.0466666666667\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "#print('err : ', 1 - metrics['ACCURACY'])\n",
    "print('err : ', 1 - acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color='#28B463'>Considerations\n",
    "\n",
    "<br>\n",
    "<b>We really can't tell whether the model simply memorized the training data or if it is actually able to generalize well to new, unseen data</b>.\n",
    "\n",
    "<font color='#28B463'><b>Note</b></font> : see Hold-Out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## <font color='#28B463'>References\n",
    "\n",
    "<br>\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "        Sebastian Raschka - Model evaluation, model selection, and algorithm selection in machine learning - Part I <br>\n",
    "        https://sebastianraschka.com/blog/2016/model-evaluation-selection-part1.html\n",
    "    </li>\n",
    "</ul>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
