# ds-knowledge-notebooks
A collection of Jupyter Notebooks : my understanding of theoretical and practical topics of Data Science

# <a id="table-of-contents">Table of Contents

* [Pre-Processing](#pre-processing)
* [Performance Metrics](#performance-metrics)
* [Model Evaluation](#model-evaluation)
* [Regression](#regression)
* [Regularized Regression](#regularized-regression)
* [Decision Tree Learning](#decision-tree-learning)
* [Neural Networks](#neural-networks)
* [Bayesian Learning](#bayesian-learning)
* [Ensemble Methods](#ensemble-methods)
* [Clustering](#clustering)


<br>
<hr>
<br>


### <a id="pre-processing">Pre-Processing</a>
[[back to top]](#table-of-contents)

* [Scaling and Normalization]()
* [Feature Extraction]()
* [Feature Selection]
* [Dimensionality Reduction]


<br>
<hr>
<br>

### <a id="performance-metrics">Performance Metrics</a>
[[back to top]](#table-of-contents)

* [Regression Metrics]()
* [Classification Metrics]()


<br>
<hr>
<br>


### <a id="#model-evaluation">Model Evaluation</a>
[[back to top]](#table-of-contents)

* [Resubstitution]()
* [Hold Out]()
* [Repeated Hold Out]()
* [Stratified Hold Out]()
* [Repeated Stratified Hold Out]()
* Cross Validation
  * [K-Fold Cross Validation]()
  * [2-Fold Cross Validation]()
  * [M-Fold Cross Validation]()
  * [The Choice of K]()
  * [Repeated K-Fold Cross Validation]()
* [Bootstrap]()


<br>
<hr>
<br>


### <a id="regression">Regression</a>
[[back to top]](#table-of-contents)

* [Introduction]()
* [CLRM Assumptions]()
* Violation of CLRM Assumptions
  * [Residual Analysis]()
  * [Violation of Linearity]()
  * [Violation of Exogeneity]()
  * [Violation of Homoscedasticity]()
  * [Violation of Indipendence of the Error Terms]()
  * [Violation of Multicollinearity]()

* Estimation
  * [Statistical Properties]()
  * [Estimation Methods]()


<br>
<hr>
<br>


### <a id="regularized-regression">Regularized Regression</a>
[[back to top]](#table-of-contents)

* [Ridge Regression]()
* [Least Absolute Shrinkage and Selection Operator (LASSO)]()
* [Elastic Net]()
* [Least Angle Regression (LARS)]


<br>
<hr>
<br>


### <a id="decision-tree-learning">Decision Tree Learning</a>
[[back to top]](#table-of-contents)

* [Classification and Regression Tree (CART)]
* [Iterative Dichotomiser 3 (ID3)]
* [C4.5 and C5.0]
* [Chi-square Automatic Interaction Detection (CHAID)]
* [Decision Stump]
* [Conditional Decision Tree]
* [M5]


<br>
<hr>
<br>


### <a id="neural networks">Neural Networks</a>
[[back to top]](#table-of-contents)

* [Introduction]()
* [Activation Functions]()
* Learning Algorithms
  * [The Perceptron Rule]()
  * [The Delta Rule]()
  * [Back Propagation]()
* [Perceptron]()
* [Multi Layer Perceptron]()
* [Deep Neural Network]
* [Convolutional Neural Network]
* [Recurrent Neural Network]


<br>
<hr>
<br>


### <a id="bayesian-learning">Bayesian Learning</a>
[[back to top]](#table-of-contents)

* []()
* []()


<br>
<hr>
<br>


### <a id="ensemble-methods">Ensemble Methods</a>
[[back to top]](#table-of-contents)

* []()
* []()


<br>
<hr>
<br>


### <a id="clustering">Clustering</a>
[[back to top]](#table-of-contents)

* []()
* []()
