{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATISTICAL PROPERTIES\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "<br>\n",
    "Depending on the estimator we choose to use, and (within that specific estimator) on the assumptions satisfied, our estimates will show a different behavior on a number of statistical properties, which we will discuss shortly. \n",
    "\n",
    "<br>\n",
    "These statistical properties are extremely important because they provide criteria for choosing among alternative estimators. Knowledge of these properties is therefore essential to understand why we use a certain estimation procedure under certain conditions.\n",
    "\n",
    "<br>\n",
    "There are two categories of statistical properties : <br>\n",
    "\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "        <b>finite-sample</b> (or small-sample) <b>properties</b>; the most desirable finite-sample properties of an estimator\n",
    "        are unbiasedness, minimum variance, and efficiency <br>\n",
    "        [<b>F1 - F3</b>]\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <b>asymptotic</b> (or large-sample) <b>properties</b>; the most desirable asymptotic property of an estimator is\n",
    "        consistency <br>\n",
    "        [<b>A1</b>]\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "Both sets of statistical properties refer to the properties of the sampling distribution (or probability distribution) of the estimator $\\hat{\\boldsymbol{\\beta}}$ for different sample sizes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite-Sample Properties\n",
    "\n",
    "<br>\n",
    "The finite-sample properties of the estimator refer to the properties of the sampling distribution of $\\hat{\\boldsymbol{\\beta}}$ for any sample of fixed size N, where N is a finite number denoting the number of observations in the sample. In fact, there is a family of finite-sample distributions for the estimator, one for each finite value of N.\n",
    "\n",
    "<br>\n",
    "The sampling distribution of $\\hat{\\boldsymbol{\\beta}}$ is based on the concept of repeated sampling : <br>\n",
    "\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "        suppose a large number of samples of size N are randomly selected from some underlying population; each of these samples\n",
    "        contains N observations and (in general) different sample values of the observable random variables\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        for each of these samples of N observations, the estimator for $\\hat{\\boldsymbol{\\beta}}$ is used to compute a numerical\n",
    "        estimate of the unknown population parameter $\\boldsymbol{\\beta}$, and each sample yields a different numerical estimate \n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        if we tabulate or plot these different sample estimates of the parameter $\\boldsymbol{\\beta}$ for a very large number of\n",
    "        samples of size N, we obtain the finite-sample distribution of the estimator $\\hat{\\boldsymbol{\\beta}}$\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "The finite-sample distribution of the estimator $\\hat{\\boldsymbol{\\beta}}$ for any finite sample size N has two characteristic values : a mean (or expectation) and a variance, respectively denoted as $\\mathbf{E}(\\hat{\\boldsymbol{\\beta}})$ and $\\mathrm{Var}(\\hat{\\boldsymbol{\\beta}})$. It's in terms of these two values (mean and variance) of the finite-sample distribution of the estimator $\\hat{\\boldsymbol{\\beta}}$ that we define the finite-sample properties of the estimator itself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [F1] Unbiasedness\n",
    "\n",
    "<br>\n",
    "The estimator $\\hat{\\boldsymbol{\\beta}}$ is said to be an <b>unbiased</b> estimator of the corresponding population parameter if the mean (or expectation) of the finite-sample distribution of $\\hat{\\boldsymbol{\\beta}}$ is equal to the true value $\\boldsymbol{\\beta}$ : <br>\n",
    "\n",
    "$ \n",
    "    \\quad \n",
    "    \\mathbf{E}(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta} \\quad \\text{for any given finite sample size } 0 < N < \\infty \n",
    "$\n",
    "\n",
    "<br>\n",
    "The <b>bias</b> of the estimator $\\hat{\\boldsymbol{\\beta}}$ is defined as $ \\Big[ \\mathbf{E}(\\hat{\\boldsymbol{\\beta}}) - \\boldsymbol{\\beta} \\Big] $; the estimator $\\hat{\\boldsymbol{\\beta}}$ is said to be : <br>\n",
    "\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "        <b>upward biased</b> (or positively biased) if the bias is greater than zero \n",
    "        $ \\quad \\Big( \\mathbf{E}[\\hat{\\boldsymbol{\\beta}}] - \\boldsymbol{\\beta} > 0 \\Big) $\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <b>downward biased</b> (or negatively biased) if the bias is less than zero \n",
    "        $ \\quad \\Big( \\mathbf{E}[\\hat{\\boldsymbol{\\beta}}] - \\boldsymbol{\\beta} < 0 \\Big) $\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "If the estimator is unbiased, it means that on average it's correct, even though any single estimate for a particular sample of data may not equal $\\boldsymbol{\\beta}$. More technically, it means that the finite-sample distribution of the\n",
    "estimator is centered on the value $\\boldsymbol{\\beta}$, rather than some other real value. \n",
    "\n",
    "<br>\n",
    "The bias of an estimator is an inverse measure of its average accuracy; the smaller in absolute value is the bias, the more accurate on average is the estimator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [F2] Minimum Variance\n",
    "\n",
    "<br>\n",
    "The estimator $\\hat{\\boldsymbol{\\beta}}$ is said to be a minimum-variance estimator of the corresponding population parameter if the variance of the finite-sample distribution of $\\hat{\\boldsymbol{\\beta}}$ is less than or equal to the variance of the finite-sample distribution of $\\tilde{\\boldsymbol{\\beta}}$, where the latter is any other estimator of the same population parameter :\n",
    "\n",
    "$\n",
    "    \\quad \n",
    "    \\mathrm{Var}(\\hat{\\boldsymbol{\\beta}}) \\ \\leq \\ \\mathrm{Var}(\\tilde{\\boldsymbol{\\beta}})\n",
    "    \\quad \\text{for any given finite sample size } 0 < m < \\infty \n",
    "$\n",
    "\n",
    "<br>\n",
    "The variance of an estimator is an inverse measure of its statistical precision, i.e. of its dispersion around the mean. The smaller the variance of an estimator, the more statistically precise it is. \n",
    "\n",
    "<br>\n",
    "It's essential to notice that the statistical property of minimum variance implies nothing about the estimators being biased or\n",
    "unbiased. \n",
    "\n",
    "<br>\n",
    "A minimum variance estimator is therefore the statistically most precise estimator of an unknown population parameter, although it may be biased or unbiased. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [F3] Efficiency\n",
    "\n",
    "<br>\n",
    "The finite-sample property of efficiency is defined only for unbiased estimators. Equivalently, a necessary condition for efficiency of the estimator $\\hat{\\boldsymbol{\\beta}}$ is that it must be an unbiased estimator of the corresponding population parameter.\n",
    "\n",
    "<br>\n",
    "Let $\\hat{\\boldsymbol{\\beta}}$ and $\\tilde{\\boldsymbol{\\beta}}$ be two unbiased estimators of the same population parameter $\\boldsymbol{\\beta}$, then the estimator $\\hat{\\boldsymbol{\\beta}}$ is efficient relative to the estimator $\\tilde{\\boldsymbol{\\beta}}$ if the variance of the finite-sample distribution of the former is less than or at most equal to the variance of the finite-sample distribution of the latter.\n",
    "\n",
    "<br>\n",
    "<b>Efficiency = Unbiasedness + Minimum Variance</b>\n",
    "\n",
    "<br>\n",
    "Efficiency is a desirable statistical property because it provides a criterion for choosing among a number of unbiased estimators the one showing the minimum dispersion around its mean, the most precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asymptotic Properties\n",
    "\n",
    "<br>\n",
    "The asymptotic (or large-sample) properties of an estimator $\\hat{\\boldsymbol{\\beta}}$ refer to the properties of the sampling distribution of that estimator as the sample size N becomes very (or indefinitely) large, as N approaches infinity.\n",
    "\n",
    "<br>\n",
    "The sampling distribution of an estimator $\\hat{\\boldsymbol{\\beta}}$ differs for different sample sizes; in general, the sampling distributions of $\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m_1}}$ and $\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m_2}}$ will be different in terms of means, variances, mathematical forms.\n",
    "\n",
    "<br>\n",
    "The most desirable asymptotic properties of an estimator are : <br>\n",
    "\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "        <b>Consistency</b>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <b>Asymptotic Unbiasedness</b>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        <b>Asymptotic Efficiency</b>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "Before we dive into the details of these large-sample properties, we first need to distinguish between two sampling distributions of the estimator: the <b>asymptotic distribution</b> and the <b>ultimate (or final) distribution</b>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asymptotic and Ultimate distributions\n",
    "\n",
    "<br>\n",
    "The <b>asymptotic</b> distribution of an estimator is the distribution to which the sampling distribution of the estimator finally converges as sample size m approaches infinity.\n",
    "\n",
    "<br>\n",
    "For many estimators, the sampling distribution collapses to a single point as sample size m approaches infinity: <br>\n",
    "\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "        more specifically, as sample size $m \\rightarrow \\infty$, the sampling distribution of the estimator collapses to\n",
    "        a column of unit probability mass (or unit probability density) at a single point on the real line\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        such an estimator is said to converge in probability to some value\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        a distribution that is completely concentrated at one point (on the real line) is called a degenerate distribution.\n",
    "        Graphically, a degenerate distribution is represented by a perpendicular to the real line with height equal to one \n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "The <b>ultimate</b> distribution of an estimator is the distribution to which the sampling distribution of the estimator converges as sample size m \"reaches\" infinity. \n",
    "\n",
    "<br>\n",
    "We can now define the asymptotic distribution of an estimator as the distribution to which the sampling distribution of the estimator converges just before it collapses (if it does) as sample size m approaches infinity. If the ultimate distribution of an estimator is degenerate, then its asymptotic distribution is not identical to its ultimate distribution. If the ultimate distribution of an estimator is non-degenerate, then its asymptotic distribution is identical to its ultimate distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [A1] Consistency\n",
    "\n",
    "<br>\n",
    "The estimator $\\hat{\\boldsymbol{\\beta}}$ is a consistent estimator of the population parameter $\\boldsymbol{\\beta}$ if its sampling distribution converges to (or collapses on) the value of the population parameter as $m \\rightarrow \\infty$ : <br>\n",
    "\n",
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\quad\n",
    "        & \\quad p\\lim_{m \\rightarrow \\infty}\n",
    "          \\hat{\\boldsymbol{\\beta}} = \\boldsymbol{\\beta}\n",
    "        & \\text{the estimator }\n",
    "          \\hat{\\boldsymbol{\\beta}} \n",
    "          \\text{ converges in probability to the population parameter } \n",
    "          \\boldsymbol{\\beta}\n",
    "        \\newline\n",
    "        \\text{or} & \\quad p\\lim_{m \\rightarrow \\infty} \n",
    "                    Pr \\Big( \\lvert \\hat{\\boldsymbol{\\beta}} - \\boldsymbol{\\beta} \\rvert \\Big) = 1 \n",
    "        & \\text{the probability that }\n",
    "          \\hat{\\boldsymbol{\\beta}} \n",
    "          \\text{ is arbitrarily close to }\n",
    "          \\boldsymbol{\\beta} \n",
    "          \\text{ approaches 1 as the sample size }\n",
    "          m \\rightarrow \\infty\n",
    "    \\end{align}\n",
    "$\n",
    "\n",
    "<br>\n",
    "It means that, as the sample size $m$ becomes larger and larger (approches infinity) : <br>\n",
    "\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "         the sampling distribution of the estimator $\\hat{\\boldsymbol{\\beta}}$ becomes more and more concentrated around\n",
    "         $\\boldsymbol{\\beta} $\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "         the value returned by the estimator (the estimate) is more and more likely to be very close to $\\boldsymbol{\\beta}$\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "Definition of the probability limit and more details in the appendix <b>AX1</b>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [A1] Consistency - A Necessary Condition\n",
    "\n",
    "<br>\n",
    "Let $\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}}$ be an estimator of the population parameter $\\boldsymbol{\\beta}$ based on a sample of size $m$ observations. \n",
    "\n",
    "<br>\n",
    "A necessary condition for consistency of the estimator is for the ultimate distribution of $\\hat{\\boldsymbol{\\beta}}$ to be a degenerate distribution at some point on the real line, i.e. to converge to a single point on the real line. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [A1] Consistency - A Sufficient Condition\n",
    "\n",
    "<br>\n",
    "Let $\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}}$ be an estimator of the population parameter $\\boldsymbol{\\beta}$ based on a sample of size $m$ observations. \n",
    "\n",
    "<br>\n",
    "If both the bias and variance of the estimator $\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{N}}$ approach zero as the sample size $m$ approaches infinity, then $\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}}$ is a consistent estimator of $\\boldsymbol{\\beta}$ : <br>\n",
    "\n",
    "$\n",
    "    \\quad\n",
    "    \\lim_{m \\rightarrow \\infty} \\text{Bias}(\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}}) = 0\n",
    "    \\quad \\text{or} \\quad\n",
    "    \\lim_{m \\rightarrow \\infty} \\mathbf{E}(\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}}) = \\boldsymbol{\\beta}\n",
    "    \\quad \\textbf{and} \\quad\n",
    "    \\lim_{m \\rightarrow \\infty} \\mathrm{Var}(\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}}) = 0    \n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [AX-1] Probability Limit\n",
    "\n",
    "<br>\n",
    "Let $\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}}$ be an estimator of the population parameter $\\boldsymbol{\\beta}$ with a degenerate ultimate distribution, i.e. the sampling distribution of $\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}}$ collapses to a column of unit density as the sample size approaches infinity.\n",
    "\n",
    "<br>\n",
    "The point $\\boldsymbol{\\beta_0}$ on which the ultimate sampling distribution converges is called the <b>probability limit</b> of $\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}}$ and is denoted as \n",
    "$ p\\lim \\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}} $ or \n",
    "$ p\\lim_{m \\rightarrow \\infty} \\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}} $ :\n",
    "\n",
    "$\n",
    "    \\quad\n",
    "    \\begin{align*}\n",
    "        &\n",
    "        \\begin{aligned}[T]\n",
    "            \\lim_{m \\rightarrow \\infty} Pr\n",
    "            \\Big(\n",
    "                \\boldsymbol{\\beta_0} - \\boldsymbol{\\varepsilon} \\leq\n",
    "                \\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}} \\leq\n",
    "                \\boldsymbol{\\beta_0} + \\boldsymbol{\\varepsilon}\n",
    "            \\Big) &=\n",
    "            \\newline\n",
    "            &= \\lim_{m \\rightarrow \\infty} Pr\n",
    "            \\Big(\n",
    "                - \\boldsymbol{\\varepsilon} \\leq\n",
    "                \\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}} - \\boldsymbol{\\beta_0} \\leq\n",
    "                + \\boldsymbol{\\varepsilon}\n",
    "            \\Big)\n",
    "            \\newline\n",
    "            &= \\lim_{N \\rightarrow \\infty} Pr\n",
    "            \\Big( \n",
    "                \\lvert \\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}} - \\boldsymbol{\\beta_0} \\rvert \\leq \\boldsymbol{\\varepsilon}\n",
    "            \\Big)\n",
    "            \\newline\n",
    "            &= 1\n",
    "        \\end{aligned}\n",
    "    \\end{align*}\n",
    "$\n",
    "\n",
    "where $\\boldsymbol{\\varepsilon}$  is an arbitrarily small positive number.\n",
    "\n",
    "<br>\n",
    "As sample size $m \\rightarrow \\infty$, the estimator $\\hat{\\boldsymbol{\\beta}}_{\\boldsymbol{m}}$ \"converges in probability\" to the point $\\boldsymbol{\\beta_0}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<br>\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "        Queen's University at Kingston - Economics 351 - M.G. Abbott -\n",
    "        <a href=\"https://bit.ly/2kqeRUV\">\n",
    "        Desirable Statistical Properties of Estimators</a>        \n",
    "    </li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
