{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERALIZED LEAST SQUARES\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "<br>\n",
    "Until now we have assumed the error terms to be spherical ($ \\ \\mathbf{E} [ \\varepsilon \\varepsilon^{\\top} \\mid X ] = \\sigma^2 \\textit{I} \\ $). Although the assumptions of homoscedasticity and indipendence of the error terms have no effect on the OLS method per se, we will see that they do affect the statistical properties of the OLS estimators and resulting test statistics. \n",
    "\n",
    "<b>Generalized least squares</b> (<b>GLS</b>) is an extension of the OLS method that allows unbiased and efficient estimation of population parameters $\\boldsymbol{\\beta}$ when the error terms are affected by either <b>heteroscedasticity or correlations (or both)</b>, as long as the form of heteroscedasticity and correlation is known independently of the data. \n",
    "\n",
    "<br>\n",
    "GLS can be used to perform linear regression when there is a certain degree of correlation between the residuals in a regression model. In these cases, OLS and weighted least squares can be statistically inefficient, or even give misleading inferences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with OLS\n",
    "\n",
    "<br>\n",
    "A quick look at the previous notebooks will remind us that :\n",
    "\n",
    "<br>\n",
    "<blockquote>\n",
    "$\n",
    "    \\begin{align}\n",
    "        &\n",
    "            \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \n",
    "            \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad\n",
    "            \\text{by OLS estimation}\n",
    "        \\newline\n",
    "        \\hat{\\boldsymbol{\\beta}}_\\boldsymbol{OLS-1}\n",
    "        &= (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{X}^{\\top}\\mathbf{Y}         \n",
    "        \\newline\n",
    "        &= {\\boldsymbol{\\beta}} + (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{X}^{\\top}\\boldsymbol{\\varepsilon}\n",
    "    \\end{align}\n",
    "    \\\\\n",
    "    \\hat{\\boldsymbol{\\beta}}_\\boldsymbol{OLS-0} \n",
    "    = \\overline{\\mathbf{Y}} - \\hat{\\boldsymbol{\\beta}}_\\boldsymbol{OLS-1} \\overline{\\mathbf{X}}\n",
    "$\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "$\n",
    "    \\begin{align}\n",
    "        &\n",
    "            \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \n",
    "            \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad\n",
    "            & \\text{by strinct exogeneity (} \\textbf{A2} \\text{)}  \n",
    "        \\newline\n",
    "        & \\mathbf{E} \\big[ \\boldsymbol{\\hat{\\beta}_{OLS-1}} \\big] = \\boldsymbol{\\beta_1}\n",
    "        \\newline\n",
    "        & \\mathbf{E} \\big[ \\boldsymbol{\\hat{\\beta}_{OLS-0}} \\big] = \\boldsymbol{\\beta_0}\n",
    "    \\end{align}\n",
    "$\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "$\n",
    "    \\begin{align}\n",
    "        &\n",
    "            \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \n",
    "            \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad\n",
    "            & \\text{by strinct exogeneity (} \\textbf{A2} \\text{)}  \n",
    "        \\newline\n",
    "        & \\mathrm{Var}(\\boldsymbol{\\mathbf{Y}_i}) = \\mathrm{Var} ( \\boldsymbol{\\varepsilon_i} )\n",
    "        \\newline\n",
    "        & \\mathrm{V}(\\mathbf{Y}) = \\mathrm{V}(\\boldsymbol{\\varepsilon})\n",
    "        \\newline\n",
    "        & \\mathrm{V}(\\hat{\\boldsymbol{\\beta}}_\\boldsymbol{OLS}) \n",
    "        = \n",
    "            (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{X}^{\\top}\n",
    "            \\ \\mathrm{V}(\\boldsymbol{\\varepsilon}) \\         \n",
    "            \\mathbf{X} (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}  \n",
    "    \\end{align}\n",
    "$\n",
    "</blockquote>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Suppose now that instead of $\\quad \\mathrm{V}(\\boldsymbol{\\varepsilon}) = \\boldsymbol{\\sigma^2} \\boldsymbol{\\textit{I}} \\quad$, the covariance matrix of the disturbance term is $ \\quad \\mathrm{V}(\\boldsymbol{\\varepsilon}) = \\boldsymbol{\\Sigma} = \\boldsymbol{\\sigma^2} \\ \\mathbf{\\Omega} \\quad $, where the matrix $\\mathbf{\\Omega}$ is a positive definite matrix accounting for both heteroscedasticity and autocorrelation.\n",
    "\n",
    "<br>\n",
    "Since the only assumption required for unbiasedness is strict exogeneity, if we were to estimate our model using OLS, <b>our estimators will still be unbiased</b>.\n",
    "\n",
    "<br>\n",
    "We also know that $\\mathrm{V}(\\boldsymbol{\\varepsilon})$ is no longer a scalar covariance matrix, and hence there is no guarantee that the OLS estimator is the most efficient within the class of linear unbiased estimators (<b>loss of efficiency</b>).\n",
    "\n",
    "<br>\n",
    "Apart from efficiency, a more serious consequence is that <b>hypothesis testing based on the standard OLS estimation becomes invalid</b> : as the <b><i>t</i></b> and <b><i>F</i></b> statistics depend on the elements of the estimated covariance matrix \n",
    "$ \\boldsymbol{s^2} \\ (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} $, they no longer have the desired t and F distributions under the null hypothesis. Consequently, the inferences based on these tests become invalid.\n",
    "\n",
    "<br>\n",
    "In practice, we hardly know the true properties of $\\mathbf{Y}$; therefore it is important to consider an estimation method that is valid when $\\mathrm{Var}(\\mathbf{Y})$ has a more general form.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivation\n",
    "\n",
    "<br>\n",
    "The intuition behind GLS is to find a transformation $\\mathbf{G}$ (of the population regression equation) such that it delivers a new error term which actually meets the Gauss-Markov assumptions, while retaining the others made so far. If the new specification complies with the Gauss-Markov assumptions, then it is proven that the OLS estimator will be BLUE. \n",
    "\n",
    "<br>\n",
    "Let $\\mathbf{G}$ be a $_\\textit{ N x N }$ non-stochastic matrix, now consider the \"transformed\" specification\n",
    "\n",
    "<br>\n",
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        &\n",
    "            \\mathbf{G} \\ \\mathbf{Y} = \\mathbf{G} \\ \\mathbf{X} \\ \\boldsymbol{\\beta} + \\mathbf{G} \\ \\boldsymbol{\\varepsilon} \n",
    "        \\newline\n",
    "        \\text{or} \\quad\n",
    "        &\n",
    "            \\boldsymbol{\\mathbf{Y}^*} = \\boldsymbol{\\mathbf{X}^*} \\ \\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon^*} \n",
    "    \\end{align}\n",
    "$\n",
    "\n",
    "<br>\n",
    "where $\\boldsymbol{\\mathbf{Y}^*} (=\\mathbf{G} \\ \\mathbf{Y}) $ denotes the transformed dependent variable and \n",
    "$ \\boldsymbol{\\mathbf{X}^*} (= \\mathbf{G} \\ \\mathbf{X})$ is the matrix of transformed explanatory variables.\n",
    "\n",
    "<br>\n",
    "It can be seen that $\\boldsymbol{\\mathbf{X}^*}$ has full column rank $\\textit{p}$, provided that $\\mathbf{G}$ is nonsingular; the identification requirement thus carries over under nonsingular transformations. It follows that population parameters can still be estimated by OLS using these transformed variables.\n",
    "\n",
    "<br>\n",
    "It is also easy to see that the specification is still linear with respect to the parameters \n",
    "\n",
    "<br>\n",
    "Before going through the OLS estimation of the parameters, let's ask ourselves what are the properties brought by this transformation $\\mathbf{G}$ ? Without further assumptions or knowledge, we can say that :\n",
    "\n",
    "<br>\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "        $            \n",
    "            \\mathbf{E}[\\boldsymbol{\\varepsilon^*}] \n",
    "            \\ = \\ \\mathbf{E}[\\mathbf{G} \\boldsymbol{\\varepsilon}] \n",
    "            \\ = \\ \\mathbf{G} \\ \\mathbf{E}[\\boldsymbol{\\varepsilon}] \n",
    "            \\ = \\ 0                        \n",
    "        $    \n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        $\n",
    "            \\mathbf{E}[\\boldsymbol{\\varepsilon^*}\\boldsymbol{\\varepsilon^{*\\top}}]\n",
    "            \\ = \\ \\mathbf{E}[ \\ (\\mathbf{G} \\ \\boldsymbol{\\varepsilon}) \\ (\\mathbf{G} \\ \\boldsymbol{\\varepsilon})^{\\top} \\ ] \n",
    "            \\ = \\ \\mathbf{E}[ \\ \\mathbf{G} \\ \\boldsymbol{\\varepsilon} \\ \\boldsymbol{\\varepsilon}^{\\top} \\ \\mathbf{G}^{\\top} \\ ]\n",
    "            \\ = \\ \\mathbf{G} \\ \\mathbf{E}[ \\ \\boldsymbol{\\varepsilon} \\ \\boldsymbol{\\varepsilon}^{\\top} \\ ] \\ \\mathbf{G}^{\\top} \n",
    "            \\ = \\ \\mathbf{G} \\ \\mathbf{\\Sigma} \\ \\mathbf{G}^{\\top} \n",
    "            \\ = \\ \\boldsymbol{\\sigma^2} \\ \\mathbf{G} \\ \\mathbf{\\Omega} \\ \\mathbf{G}^{\\top}    \n",
    "        $    \n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        $\n",
    "            \\mathbf{E}[\\mathbf{Y^*}] \n",
    "            \\ = \\ \\mathbf{E}[\\boldsymbol{\\mathbf{X}^*} \\ \\boldsymbol{\\beta}] + \\mathbf{E}[\\boldsymbol{\\varepsilon^*}]\n",
    "            \\ = \\ \\mathbf{E}[\\mathbf{G} \\ \\mathbf{X} \\ \\boldsymbol{\\beta}]\n",
    "            \\ = \\ \\mathbf{G} \\ \\mathbf{E}[\\mathbf{X} \\ \\boldsymbol{\\beta}]\n",
    "            \\ = \\ \\mathbf{G} \\ \\mathbf{E}[\\mathbf{Y}]\n",
    "        $    \n",
    "    </li>\n",
    "</ul>    \n",
    "\n",
    "<br>\n",
    "The resulting OLS estimators are : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\boldsymbol{\\hat{\\beta}_{GLS-1}}\n",
    "        &= \n",
    "        \\newline\n",
    "        &= (\\mathbf{X^{*\\top}} \\mathbf{X^*})^{-1} \\mathbf{X^{*\\top}} \\mathbf{Y^*}  \n",
    "        \\newline\n",
    "        &=  \n",
    "            \\big[ (\\mathbf{G} \\ \\mathbf{X})^{\\top} (\\mathbf{G} \\ \\mathbf{X}) \\big] ^{-1} \n",
    "            (\\mathbf{G} \\ \\mathbf{X})^{\\top} (\\mathbf{G} \\ \\mathbf{Y})\n",
    "        \\newline\n",
    "        &=  \n",
    "            \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{X} \\big] ^{-1} \n",
    "            \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\mathbf{G} \\ \\mathbf{Y}   \n",
    "    \\end{align}    \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\hat{\\boldsymbol{\\beta}}_\\boldsymbol{GLS-0} \n",
    "        &= \n",
    "        \\newline\n",
    "        &= \\overline{\\mathbf{Y}}^{\\ *} - \\boldsymbol{\\hat{\\beta}_{GLS-1}} \\overline{\\mathbf{X}}^{\\ *}\n",
    "        \\newline\n",
    "        &= \\mathbf{G} \\ \\overline{\\mathbf{Y}} - \\boldsymbol{\\hat{\\beta}_{GLS-1}} \\mathbf{G} \\ \\overline{\\mathbf{X}}  \n",
    "    \\end{align}    \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\mathrm{V}(\\boldsymbol{\\varepsilon^*}) \n",
    "        &= \n",
    "        \\newline\n",
    "        &= \\mathrm{V}(\\mathbf{G} \\ \\boldsymbol{\\varepsilon}) \n",
    "        \\newline\n",
    "        &= \n",
    "            \\mathbf{G} \\ \\mathrm{V}(\\boldsymbol{\\varepsilon}) \\ \\mathbf{G}^{\\top}\n",
    "            = \\mathbf{G} \\ \\boldsymbol{\\Sigma} \\ \\mathbf{G}^{\\top}\n",
    "    \\end{align}    \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\mathrm{V}(\\boldsymbol{\\hat{\\beta}_{GLS-1}}) \n",
    "        &=\n",
    "        \\newline\n",
    "        &= \n",
    "            (\\mathbf{X^{* \\top}} \\mathbf{X^*})^{-1} \\mathbf{X^{* \\top}}\n",
    "            \\ \\mathrm{V}(\\boldsymbol{\\varepsilon^*}) \\         \n",
    "            \\mathbf{X^*} (\\mathbf{X^{* \\top}}\\mathbf{X^*})^{-1}  \n",
    "        \\newline\n",
    "        &= \n",
    "            \\big[ (\\mathbf{G} \\ \\mathbf{X})^{\\top} (\\mathbf{G} \\ \\mathbf{X}) \\big] ^{-1} \n",
    "            \\ (\\mathbf{G} \\ \\mathbf{X})^{\\top}\n",
    "            \\ (\\mathbf{G} \\ \\boldsymbol{\\Sigma} \\ \\mathbf{G}^{\\top})\n",
    "            \\ (\\mathbf{G} \\ \\mathbf{X}) \n",
    "            \\ \\big[ (\\mathbf{G} \\ \\mathbf{X})^{\\top} (\\mathbf{G} \\ \\mathbf{X}) \\big] ^{-1} \n",
    "    \\end{align}    \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\mathrm{V}(\\mathbf{Y^*}) \n",
    "        &=\n",
    "        \\newline\n",
    "        &= \\mathrm{V}(\\boldsymbol{\\varepsilon^*})  \n",
    "        = \\mathbf{G} \\ \\boldsymbol{\\Sigma} \\ \\mathbf{G}^{\\top}\n",
    "    \\end{align}    \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which we know is unbiased for any non-stochastic and non-singular matrix $\\mathbf{G}$. The next question is : can we\n",
    "find a transformation matrix that yields the most efficient estimator among all linear unbiased estimators? In other words, if there is any matrix $\\mathbf{G}$ such that $ \\mathbf{G} \\ \\mathbf{\\Omega} \\ \\mathbf{G}^{\\top} = \\boldsymbol{\\sigma^2} \\boldsymbol{\\textit{I}} $ for some finite positive number $\\boldsymbol{\\sigma^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonalizable Matrices\n",
    "\n",
    "<br>\n",
    "A square $ \\ \\textit{ m x m } \\ $ matrix $\\mathbf{A}$ is said to be diagonalizable if it can be written in the form \n",
    "$ \\quad \\mathbf{A} = \\mathbf{Q} \\ \\mathbf{D} \\ \\mathbf{Q}^{-1} \\quad $ where \n",
    "\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "        $\\mathbf{D}$ is a diagonal $ \\ \\textit{ m x m } \\ $ matrix with the eigenvalues of $\\mathbf{A}$ as its entries\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        $\\mathbf{Q}$ is a nonsingular $ \\ \\textit{ m x m } \\ $ matrix consisting of the eigenvectors corresponding to the\n",
    "        eigenvalues in $\\mathbf{D}$\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<br>\n",
    "<b>Property</b> :\n",
    "A square $ \\ \\textit{ m x m } \\ $ matrix $\\mathbf{A}$ is diagonalizable <b>if and only if</b> it has $ \\ \\textit{m} \\ $ linearly independent eigenvectors, i.e. if the rank of the matrix formed by the eigenvectors is $ \\ \\textit{m} \\ $. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Matrices\n",
    "\n",
    "<br>\n",
    "A square $ \\ \\textit{ m x m } \\ $ matrix $\\mathbf{Q}$ is said to be orthogonal if it has real entries and its columns and rows are orthogonal unit vectors (orthonormal vectors), i.e. if its transpose is equal to its inverse : \n",
    "\n",
    "$\n",
    "    \\quad\n",
    "    \\mathbf{Q}^{\\top} \\mathbf{Q} = \\mathbf{Q} \\ \\mathbf{Q}^{\\top} = \\boldsymbol{\\textit{I}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonally Diagonalizable Matrices\n",
    "\n",
    "<br>\n",
    "A square $ \\ \\textit{ m x m } \\ $ matrix $\\mathbf{A}$ is said to be orthogonally diagonalizable if there exists an orthogonal matrix $\\mathbf{Q}$ such that $\\mathbf{A} = \\mathbf{Q} \\ \\mathbf{D} \\ \\mathbf{Q}^{\\top}$, where the entries of the diagonal matrix $\\mathbf{D}$ are the eigenvalues of $\\mathbf{A}$, and the columns of $\\mathbf{Q}$ are the corresponding eigenvectors.\n",
    "\n",
    "<br>\n",
    "In other words, a square $ \\ \\textit{ m x m } \\ $ matrix $\\mathbf{A}$ is said to be orthogonally diagonalizable if it is diagonalizable by means of a orthogonal matrix $\\mathbf{Q}$ :\n",
    "\n",
    "<br>\n",
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\mathbf{A} = \\mathbf{Q} \\ \\mathbf{D} \\ \\mathbf{Q}^{-1}\n",
    "        &\\qquad \\Leftrightarrow \\qquad \n",
    "        \\mathbf{D} = \\mathbf{Q}^{-1} \\mathbf{A} \\ \\mathbf{Q}      \n",
    "        \\newline\n",
    "        \\mathbf{A} = \\mathbf{Q} \\ \\mathbf{D} \\ \\mathbf{Q}^{\\top}\n",
    "        &\\qquad \\Leftrightarrow \\qquad  \n",
    "        \\mathbf{D} = \\mathbf{Q}^{\\top} \\ \\mathbf{A} \\ \\mathbf{Q}\n",
    "    \\end{align}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Theorem</b> : Every orthogonally diagonalizable matrix is symmetric. \n",
    "<br>\n",
    "<b>Proof</b> : \n",
    "\n",
    "<br>\n",
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\mathbf{A} &= \\mathbf{Q} \\ \\mathbf{D} \\ \\mathbf{Q}^{-1} = \\mathbf{Q} \\ \\mathbf{D} \\ \\mathbf{Q}^{\\top}\n",
    "        \\newline \\newline\n",
    "        \\mathbf{A}^{\\top}            \n",
    "        &=         \n",
    "        \\newline\n",
    "        &= (\\mathbf{Q} \\ \\mathbf{D} \\ \\mathbf{Q}^{\\top})^{\\top}\n",
    "        = (\\mathbf{Q}^{\\top})^{\\top} \\ (\\mathbf{Q} \\ \\mathbf{D})^{\\top}\n",
    "        = \\mathbf{Q} \\ \\mathbf{D}^{\\top} \\ \\mathbf{Q}^{\\top} \n",
    "        \\newline\n",
    "        &= \\mathbf{Q} \\ \\mathbf{D} \\ \\mathbf{Q}^{\\top} \n",
    "        \\newline\n",
    "        &= \\mathbf{A}\n",
    "    \\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Theorem</b> : Every symmetric matrix is orthogonally diagonalizable.\n",
    "<br>\n",
    "<b>Proof</b> : Every (real) $ \\ \\textit{ m x m } \\ $ symmetric matrix has $\\textit{m}$ real eigenvalues (counted by their multiplicities); for each eigenvalue, we can find a real eigenvector associated with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We are now ready to prove main theorem regarding orthogonally diagonalizable matrices.\n",
    "\n",
    "<br>\n",
    "<b>The Spectral Theorem</b> : A (real) matrix is orthogonally diagonalizable <b>if and only if</b> is symmetric.\n",
    "\n",
    "<br>\n",
    "Earlier, we made the easy observation that if $\\mathbf{A}$ is orthogonally diagonalizable, then it is\n",
    "<b>necessary</b> that $\\mathbf{A}$ be symmetric. The Spectral Theorem says that the symmetry of $\\mathbf{A}$is also \n",
    "<b>sufficient</b> : a real symmetric matrix must be orthogonally diagonalizable. This is the part of the\n",
    "theorem that is hard and that seems surprising because i'is not easy to see whether a matrix is diagonalizable at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal Diagonalization at work\n",
    "\n",
    "<br>\n",
    "It is now easy to understand that in order to address the loss of efficiency due to heteroscedasticity and/or correlation,  we should choose a non-stochastic and non-singular matrix $\\mathbf{G}$ such that $ \\mathbf{G} \\ \\mathbf{\\Sigma} \\ \\mathbf{G}^{\\top} = \\boldsymbol{c^2} \\boldsymbol{\\textit{I}} $ for some finite positive number $\\boldsymbol{c^2}$.\n",
    "\n",
    "<br>\n",
    "To find the desired transformation matrix $\\mathbf{G}$, note that $\\mathbf{\\Sigma}$ is a symmetric and positive definite matrix so that it can be orthogonally diagonalized as $ \\mathbf{C} \\ \\mathbf{\\Sigma} \\ \\mathbf{C}^{\\top} = \\mathbf{\\Lambda} \\quad$ , where $\\mathbf{C}$ is the matrix of eigenvectors corresponding to the matrix of eigenvalues $\\mathbf{\\Lambda}$.\n",
    "\n",
    "<br>\n",
    "For $\\mathbf{G} = \\mathbf{\\Sigma}^{\\ -1/2} = \\mathbf{C} \\ \\mathbf{\\Lambda}^{\\ -1/2} \\ \\mathbf{C}^{\\top}$ (or $\\mathbf{\\Sigma}^{\\ -1/2} = \\mathbf{\\Lambda}^{\\ -1/2} \\ \\mathbf{C}^{\\top}$), we have\n",
    "\n",
    "<br>\n",
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\mathbf{G} \\ \\mathbf{\\Sigma} \\ \\mathbf{G}^{\\top}\n",
    "        &= \n",
    "        \\newline\n",
    "        &= \\mathbf{\\Sigma}^{\\ -1/2} \\ \\mathbf{\\Sigma} \\ (\\mathbf{\\Sigma}^{\\ -1/2})^{\\top}\n",
    "        \\newline\n",
    "        &= \\mathbf{\\Sigma}^{\\ -1/2} \\ \\mathbf{\\Sigma} \\ \\mathbf{\\Sigma}^{\\ -1/2}\n",
    "        \\newline\n",
    "        &= \\boldsymbol{c^2} \\ \\boldsymbol{\\textit{I}} _\\textit{ m x m }\n",
    "    \\end{align}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<b>Property</b> : The inverse of the orthogonally diagonalizable matrix $\\mathbf{\\Sigma}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        & \n",
    "            \\mathbf{G} \\ \\mathbf{\\Sigma} \\ \\mathbf{G}^{\\top}\n",
    "            = \\boldsymbol{c^2} \\ \\boldsymbol{\\textit{I}}\n",
    "        \\newline\n",
    "        \\Rightarrow \\quad\n",
    "        & \\mathbf{G} \\ \\mathbf{\\Sigma} \\ \\mathbf{G}^{-1} = \\boldsymbol{c^2} \\ \\boldsymbol{\\textit{I}}\n",
    "    \\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        &\n",
    "            \\mathbf{G}^{-1} \\ \\big[ \\mathbf{G} \\ \\mathbf{\\Sigma} \\ \\mathbf{G}^{-1} \\big] \\ \\mathbf{G}\n",
    "            = \\mathbf{G}^{-1} \\ (\\boldsymbol{c^2} \\ \\boldsymbol{\\textit{I}}) \\ \\mathbf{G}\n",
    "        \\newline\n",
    "        \\Rightarrow \\quad\n",
    "        &\n",
    "            \\mathbf{\\Sigma} = \\boldsymbol{c^2} \\ \\mathbf{G}^{-1} \\ \\mathbf{G}\n",
    "    \\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align} \n",
    "        \\mathbf{\\Sigma}^{-1} \n",
    "        &=\n",
    "        \\newline\n",
    "        &= \n",
    "            (\\boldsymbol{c^2} \\ \\mathbf{G}^{-1} \\ \\mathbf{G})^{-1}\n",
    "            = (\\boldsymbol{c^2})^{-1} \\ (\\mathbf{G}^{-1} \\ \\mathbf{G})^{-1}\n",
    "        \\newline\n",
    "        &= (\\boldsymbol{c^2})^{-1} \\ \\mathbf{G}^{-1} \\ \\mathbf{G}\n",
    "        \\newline\n",
    "        &= (\\boldsymbol{c^2})^{-1} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G}                        \n",
    "    \\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\mathbf{G}^{\\top} \\ \\mathbf{G} = \\boldsymbol{c^2} \\ \\mathbf{\\Sigma}^{-1} _\\textit{ m x m }\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\mathbf{G} \\ \\mathbf{\\Sigma}^{-1} \\ \\mathbf{G}^{\\top} \n",
    "        &=\n",
    "        \\newline\n",
    "        &= \\mathbf{G} \\ \\big[ (\\boldsymbol{c^2})^{-1} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\big] \\ \\mathbf{G}^{\\top}\n",
    "        \\newline\n",
    "        &= (\\boldsymbol{c^2})^{-1} \\ \\mathbf{G} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{G}^{\\top}\n",
    "        \\newline\n",
    "        &= (\\boldsymbol{c^2})^{-1} \\ \\mathbf{G} \\ \\mathbf{G^{-1}} \\ \\mathbf{G} \\ \\mathbf{G^{-1}}\n",
    "        \\newline\n",
    "        &= (\\boldsymbol{c^2})^{-1} \\ \\boldsymbol{\\textit{I}} _\\textit{ m x m }\n",
    "    \\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLUE\n",
    "\n",
    "<br>\n",
    "The OLS estimators of this specific transformation is (by construction) BLUE :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\boldsymbol{\\hat{\\beta}_{GLS-1}}\n",
    "        &= \n",
    "        \\newline\n",
    "        &=  \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{X} \\big] ^{-1} \n",
    "            \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\mathbf{G} \\ \\mathbf{Y}   \n",
    "        \\newline\n",
    "        &=  \\big[ \\mathbf{X}^{\\top} \\ \\boldsymbol{c^2} \\ \\mathbf{\\Sigma}^{-1} \\ \\mathbf{X} \\big] ^{-1} \n",
    "            \\mathbf{X}^{\\top} \\ \\boldsymbol{c^2} \\ \\mathbf{\\Sigma}^{-1} \\ \\mathbf{Y}   \n",
    "        \\newline\n",
    "        &=  \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{\\Sigma}^{-1} \\ \\mathbf{X} \\big] ^{-1} \n",
    "            \\mathbf{X}^{\\top} \\ \\mathbf{\\Sigma}^{-1} \\ \\mathbf{Y}   \n",
    "    \\end{align}    \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\mathrm{V}(\\boldsymbol{\\varepsilon^*}) \n",
    "        &= \n",
    "        \\newline\n",
    "        &= \\mathbf{G} \\ \\mathbf{\\Sigma} \\ \\mathbf{G}^{\\top}\n",
    "        \\newline\n",
    "        &= \\boldsymbol{c^2} \\boldsymbol{\\textit{I}} _\\textit{ m x m }\n",
    "    \\end{align}    \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\mathrm{V}(\\boldsymbol{\\hat{\\beta}_{GLS-1}}) \n",
    "        &=\n",
    "        \\newline\n",
    "        &= \n",
    "            \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{X} \\big] ^{-1} \n",
    "            \\ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top}  \n",
    "            \\ (\\mathbf{G} \\ \\mathbf{\\Sigma} \\ \\mathbf{G}^{\\top})\n",
    "            \\ (\\mathbf{G} \\ \\mathbf{X}) \n",
    "            \\ \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{X} \\big] ^{-1} \n",
    "        \\newline\n",
    "        &= \n",
    "            \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{X} \\big] ^{-1} \n",
    "            \\ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top}  \n",
    "            \\ (\\boldsymbol{c^2} \\boldsymbol{\\textit{I}})\n",
    "            \\ (\\mathbf{G} \\ \\mathbf{X}) \n",
    "            \\ \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{X} \\big] ^{-1} \n",
    "        \\newline\n",
    "        &= \n",
    "            \\boldsymbol{c^2}\n",
    "            \\ \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{X} \\big] ^{-1} \n",
    "            \\ \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{X} \\big]\n",
    "            \\ \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{X} \\big] ^{-1} \n",
    "        \\newline\n",
    "        &= \\boldsymbol{c^2} \\ \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{G}^{\\top} \\ \\mathbf{G} \\ \\mathbf{X} \\big] ^{-1} \n",
    "        \\newline\n",
    "        &= \\boldsymbol{c^2} \\ \\big[ \\mathbf{X}^{\\top} \\ \\boldsymbol{c^2} \\ \\mathbf{\\Sigma}^{-1} \\ \\mathbf{X} \\big] ^{-1} \n",
    "        \\newline\n",
    "        &= \\big[ \\mathbf{X}^{\\top} \\ \\mathbf{\\Sigma}^{-1} \\ \\mathbf{X} \\big] ^{-1} \n",
    "        \\newline\n",
    "    \\end{align}    \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "        \\mathrm{V}(\\mathbf{Y^*}) \n",
    "        &= \n",
    "        \\newline\n",
    "        &= \\mathrm{V}(\\boldsymbol{\\varepsilon^*}) \n",
    "        \\newline\n",
    "        & = \\boldsymbol{c^2} \\ \\boldsymbol{\\textit{I}} _\\textit{ m x m }       \n",
    "    \\end{align}    \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "As the GLS estimator does not depend on $\\boldsymbol{c}$, it is without loss of generality that we can set \n",
    "$ \\quad \\mathbf{G} = \\mathbf{\\Sigma}^{\\ -1/2} $ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of the variance\n",
    "\n",
    "<br>\n",
    "As usual, since the variance of the error terms $\\boldsymbol{\\sigma^2}$ is unobservable (being the error terms unobservable themselves), we will actually compute an estimate $\\boldsymbol{s^2}$ of it, based on the regression residuals :\n",
    "\n",
    "<br>\n",
    "$\n",
    "    \\quad\n",
    "    \\boldsymbol{{s^2}_{GLS}} \n",
    "    \\quad = \\quad\n",
    "        \\dfrac{1}{m - p} \n",
    "        \\ (\\boldsymbol{\\mathbf{Y}^{*}} - \\boldsymbol{\\mathbf{X}^{*}} \\hat{\\boldsymbol{\\beta}})^{T} \n",
    "        \\ (\\boldsymbol{\\mathbf{Y}^{*}} - \\boldsymbol{\\mathbf{X}^{*}} \\hat{\\boldsymbol{\\beta}})      \n",
    "    \\quad = \\quad \n",
    "        \\dfrac{1}{m - p} \n",
    "        \\ \\boldsymbol{c^2}\n",
    "        \\ (\\mathbf{Y} - \\mathbf{X} \\ \\hat{\\boldsymbol{\\beta}} )^{T} \n",
    "        \\ \\mathbf{\\Sigma}^{-1} \n",
    "        \\ ( \\mathbf{Y} - \\mathbf{X} \\ \\hat{\\boldsymbol{\\beta}} ) \n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimization Objective\n",
    "\n",
    "<br>\n",
    "The GLS estimator is the parameter $\\boldsymbol{\\hat{\\beta}_{GLS-1}}$ which minimizes the following criterion function :\n",
    "\n",
    "<br>\n",
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "    S_{GLS}(\\hat{\\boldsymbol{\\beta}}, \\mathbf{\\Sigma}) \n",
    "    &=\n",
    "    \\newline\n",
    "    &= \n",
    "        \\sum_{i=1}^{m} (\\boldsymbol{ {\\mathbf{e}_i}^{*} })^\\boldsymbol{2}\n",
    "        =  \\sum _{i=1}^{m} \n",
    "        \\big[ \\boldsymbol{ {\\mathbf{Y}_i}^{*} } - (\\boldsymbol{ {\\mathbf{X}_i}^{*} })^{\\top} \\hat{\\boldsymbol{\\beta}} \\big] ^{2}\n",
    "    \\newline \\newline\n",
    "    &= \n",
    "        (\\boldsymbol{\\mathbf{Y}^{*}} - \\boldsymbol{\\mathbf{X}^{*}} \\hat{\\boldsymbol{\\beta}})^{T} \\ \n",
    "        (\\boldsymbol{\\mathbf{Y}^{*}} - \\boldsymbol{\\mathbf{X}^{*}} \\hat{\\boldsymbol{\\beta}})  \n",
    "    \\newline \\newline\n",
    "    &= \n",
    "        \\big[ \\mathbf{G} \\ ( \\mathbf{Y} - \\mathbf{X} \\ \\hat{\\boldsymbol{\\beta}} ) \\big] ^{T} \\ \n",
    "        \\big[ \\mathbf{G} \\ ( \\mathbf{Y} - \\mathbf{X} \\ \\hat{\\boldsymbol{\\beta}} ) \\big]\n",
    "        \\quad = \\quad\n",
    "        \\big[ ( \\mathbf{Y} - \\mathbf{X} \\ \\hat{\\boldsymbol{\\beta}} )^{T} \\ \\mathbf{G}^{T} \\big] \\\n",
    "        \\big[ \\mathbf{G} \\ ( \\mathbf{Y} - \\mathbf{X} \\ \\hat{\\boldsymbol{\\beta}} ) \\big] \n",
    "    \\newline\n",
    "    &=\n",
    "        ( \\mathbf{Y} - \\mathbf{X} \\ \\hat{\\boldsymbol{\\beta}} )^{T} \n",
    "        \\ ( \\mathbf{G}^{T} \\ \\mathbf{G} )\n",
    "        \\ ( \\mathbf{Y} - \\mathbf{X} \\ \\hat{\\boldsymbol{\\beta}} ) \n",
    "    \\newline \\newline\n",
    "    &=\n",
    "        \\boldsymbol{c^2}\n",
    "        \\ (\\mathbf{Y} - \\mathbf{X} \\ \\hat{\\boldsymbol{\\beta}} )^{T} \n",
    "        \\ \\mathbf{\\Sigma}^{-1} \n",
    "        \\ ( \\mathbf{Y} - \\mathbf{X} \\ \\hat{\\boldsymbol{\\beta}} ) \n",
    "    \\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "    \\quad\n",
    "    \\begin{align}\n",
    "    S_{OLS}(\\hat{\\boldsymbol{\\beta}}) \n",
    "    &=\n",
    "    \\newline\n",
    "    &= \n",
    "        \\sum_{i=1}^{m} \\boldsymbol{{\\mathbf{e}_i}^2}\n",
    "        = \\sum _{i=1}^{m}(\\boldsymbol{\\mathbf{Y}_i} - \\hat{\\mathbf{Y}}_\\boldsymbol{i})^{2} \n",
    "    \\newline\n",
    "    &= (\\mathbf{Y} - \\mathbf{X} \\hat{\\boldsymbol{\\beta}})^{T} \\ (\\mathbf{Y} - \\mathbf{X} \\hat{\\boldsymbol{\\beta}})  \n",
    "    \\end{align}\n",
    "$\n",
    "\n",
    "<br>\n",
    "When compared to its OLS analogous, we will see that this criterion function is a weighted sum of squared errors and hence a <b>generalized version of the standard OLS criterion function</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feasible Generalized Least Squares\n",
    "\n",
    "<br>\n",
    "The biggest disadvantage of generalized least squares is that this method is based on the assumption that the covariance matrix of the disturbance terms is known a-priori. This is almost never the case in real applications, of course, being the error terms unobservable. It is therefore necessary to compute an estimate of this covariance matrix. \n",
    "\n",
    "<br>\n",
    "In the next notebooks we will see a special case of GLS called Weighted Least Squares, and how to estimate the covariance matrix of the original disturbance terms in order to actually implement this two methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<br>\n",
    "<ul style=\"list-style-type:square\">\n",
    "    <li>\n",
    "        National Taiwan University - Chung-Ming Kuan - \n",
    "        <a href=\"https://bit.ly/2IJ3hmG\">\n",
    "        Generalized Least Squares Theory</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        Carleton University - Ba Chu - \n",
    "        <a href=\"https://bit.ly/2J9PpB4\">\n",
    "        Generalized Least Squares Theory</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        Washington University in St. Louis - Ron Freiwald - \n",
    "        <a href=\"https://bit.ly/2s9oD1g\">\n",
    "        Orthogonally Diagonalizable Matrices</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        The University of Manchester - MATH10212 - Peter J. Eccles - \n",
    "        <a href=\"https://bit.ly/2IK3mCi\">\n",
    "        Linear Algebra : Brief Lecture Notes, Note 10</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        Wolfram MathWorld - \n",
    "        <a href=\"https://bit.ly/2Lscu09\">\n",
    "        Diagonalizable Matrix</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        Wikipedia - \n",
    "        <a href=\"https://bit.ly/2GK4LXL\">\n",
    "        Diagonalizable Matrix</a>\n",
    "    </li>\n",
    "    <br>\n",
    "    <li>\n",
    "        Wikipedia - \n",
    "        <a href=\"https://bit.ly/2vrr0wU\">\n",
    "        Orthogonal Matrix</a>\n",
    "    </li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
